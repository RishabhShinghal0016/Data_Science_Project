# -- coding: utf-8 --
"""COVID-19 Analysis Report.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TsAXP3EYHWM3-yvC6_q5TjLFF7CyOr-N
"""

# Project Title: "Analyzing Global COVID-19 Trends"

#                                                       Objective
# Analyze a dataset containing global COVID-19 case counts, vaccinations, and recovery rates to identify trends, patterns, and insights.

# Steps and Code Examples

# Step 1: Load and Explore the Data
# Dataset: Use a public COVID-19 dataset from Kaggle.

# Example: COVID-19 Dataset on Kaggle

import kagglehub

# Download latest version
path = kagglehub.dataset_download("imdevskp/corona-virus-report")

print("Path to dataset files:", path)

from google.colab import files

# This will prompt you to select a file from your local system
uploaded = files.upload()

import pandas as pd

# Load the dataset
df = pd.read_csv('covid_19_clean_complete.csv')

# View the first few rows
print(df)

import pandas as pd

# Load the dataset
df = pd.read_csv('covid_19_clean_complete.csv')
# Print all column names
print(df.columns)

import pandas as pd

# Load the dataset
df = pd.read_csv('covid_19_clean_complete.csv')

# View the first few rows
print(df.head())

import pandas as pd

# Load the dataset
df = pd.read_csv('covid_19_clean_complete.csv')

# View the first few rows
print(df.head())

# Get summary information
print(df.info())

# Data Cleaning


# Handle Missing Values

# Why?
# Missing values can lead to incorrect analysis or errors during model training.


# Identify missing values:


import pandas as pd

# Load the dataset
df = pd.read_csv('covid_19_clean_complete.csv')

# Check for missing values
print(df.isnull().sum())

import pandas as pd

# Load the dataset
df = pd.read_csv('covid_19_clean_complete.csv')

print(df[df.isnull().any(axis=1)])  # View rows with missing values

# The df.dropna() function in pandas is used to remove missing values (NaN) from a DataFrame.
# This function is highly flexible and can operate along rows or columns depending on the specified parameters.


# Syntax:

# df.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)


# Parameters
# axis:

# Determines whether to drop rows or columns.

# axis=0 (default): Drops rows containing missing values.

# axis=1: Drops columns containing missing values.

# how:

# Determines the criteria for dropping.

# 'any' (default): Drops a row or column if any value is missing.

# 'all': Drops a row or column only if all values are missing.

# thresh:

# Specifies a minimum number of non-NaN values required to keep the row or column.

# Overrides the how parameter if provided.

# subset:

# A list of column labels to consider when checking for missing values.

# Only these columns are checked for NaN values.

# inplace:

# False (default): Returns a new DataFrame with the rows/columns dropped.

# True: Modifies the original DataFrame in place and returns None.

import pandas as pd

# Load the dataset
df = pd.read_csv('covid_19_clean_complete.csv')
df.dropna(axis=0, inplace=True) # Drop rows with missing values
print(df)

import pandas as pd

# Load the dataset
df = pd.read_csv('covid_19_clean_complete.csv')
df.dropna(axis=1, inplace=True)  # Drop columns with missing values
print(df)

import pandas as pd

# Load the dataset
df = pd.read_csv('covid_19_clean_complete.csv')
# Drop rows with too many missing values
df.dropna(thresh=5, inplace=True)

print(df)

import pandas as pd

# Load the dataset
df = pd.read_csv('covid_19_clean_complete.csv')
# Fill missing values in specific columns
df['Confirmed'].fillna(0, inplace=True)
print(df)

# Detailed Explanation
# df['Confirmed_Cases']:

# Refers to the Confirmed_Cases column in the DataFrame df.

# .fillna(0):

# The fillna() method is used to replace missing values (NaN) in a column or DataFrame.

# The 0 specifies the value to use as a replacement for missing values.

# inplace=True:

# Modifies the df DataFrame directly without creating a new one.

# If inplace=False (default), it would return a new DataFrame with the changes, leaving the original unchanged.

# Why Use fillna()?
# Missing values can cause issues in analysis, calculations, or modeling.

# Filling missing values with a specific value (like 0) ensures no gaps in the data.

# Filling with 0 may be suitable for certain datasets, e.g., where 0 logically represents no cases reported.

import pandas as pd

data = {
    'Confirmed_Cases': [100, 200, None, 150],
    'Deaths': [10, 20, None, 5]
}

df = pd.DataFrame(data)
print(df)

import pandas as pd

data = {
    'Confirmed_Cases': [100, 200, None, 150],
    'Deaths': [10, 20, None, 5]
}

df = pd.DataFrame(data)
df['Confirmed_Cases'].fillna(0, inplace=True)
print(df)

import pandas as pd

# Load the dataset
df = pd.read_csv('covid_19_clean_complete.csv')
# Standardize column names
df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')
print(df)

# Detailed Breakdown
# df.columns:

# Refers to the column names of the DataFrame df.

# .str:

# Enables string operations on each column name (since df.columns is a pandas Index object).

# .strip():

# Removes leading and trailing whitespace from each column name.

# Example: ' Name ' → 'Name'.

# .lower():

# Converts all column names to lowercase.

# Example: 'Name' → 'name'.

# .replace(' ', '_'):

# Replaces spaces with underscores in column names.

# Example: 'confirmed cases' → 'confirmed_cases'.

# Why Standardize Column Names?
# Consistency: Ensures uniformity in column naming conventions.

# Ease of Use: Simplifies accessing columns programmatically (e.g., no need to handle capitalization or spaces).

# Avoid Errors: Prevents issues caused by special characters, spaces, or inconsistent naming.

import pandas as pd

data = {
    "Confirmed Cases": [100, 200, 300],
    " Deaths ": [10, 20, 30],
    "Recovery Rate (%)": [95.0, 90.0, 85.0]
}

df = pd.DataFrame(data)
print(df.columns)

import pandas as pd

data = {
    "Confirmed Cases": [100, 200, 300],
    " Deaths ": [10, 20, 30],
    "Recovery Rate (%)": [95.0, 90.0, 85.0]
}
df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')
print(df.columns)

# Step 3: Data Exploration
# Summary statistics.

# Analyze global trends.

# Identify countries with the highest cases and deaths.

# Basic Data Statistics
# df.describe():

# Provides summary statistics for numerical columns by default.

# Includes:

# count: Number of non-null values.

# mean: Average value.

# std: Standard deviation.

# min: Minimum value.

# 25%, 50%, 75%: Percentiles (Quartiles).

# max: Maximum value.

import pandas as pd

data = {
    "Age": [25, 30, 35, 40, None],
    "Salary": [50000, 60000, 70000, None, 90000],
    "Experience": [2, 5, 7, None, 12]
}

df = pd.DataFrame(data)
print(df.describe())

# Statistics for All Columns
# Include All Data Types
# To include non-numeric columns:
import pandas as pd

data = {
    "Age": [25, 30, 35, 40, None],
    "Salary": [50000, 60000, 70000, None, 90000],
    "Experience": [2, 5, 7, None, 12]
}

df = pd.DataFrame(data)

print(df.describe(include='all'))

# Additional Outputs for Non-Numeric Data:

# count: Non-null values.

# unique: Unique values.

# top: Most frequent value.

# freq: Frequency of the most frequent value.

import pandas as pd

data = {
    "Age": [25, 30, 35, 40, None],
    "Salary": [50000, 60000, 70000, None, 90000],
    "Experience": [2, 5, 7, None, 12]
}

df = pd.DataFrame(data)
print(df.count())

import pandas as pd

# Load the dataset
df = pd.read_csv('covid_19_clean_complete.csv')
print(df.columns)

import pandas as pd

# Load the dataset
df = pd.read_csv('covid_19_clean_complete.csv')
# Top 10 countries with the highest confirmed cases
top_countries = df.groupby('Country/Region')['Confirmed'].sum().sort_values(ascending=False).head(10)
print(top_countries)

import pandas as pd

# Load the dataset
df = pd.read_csv('covid_19_clean_complete.csv')
# Trend of global cases over time
global_trend = df.groupby('Date')['Confirmed'].sum()
print(global_trend)